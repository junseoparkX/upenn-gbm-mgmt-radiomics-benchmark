{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1597ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged rows with usable MGMT: 59\n",
      "X shape: (59, 135) y shape: (59,)\n",
      "Class balance (y): {0: 37, 1: 22}\n"
     ]
    }
   ],
   "source": [
    "# Build X (radiomics features) and y (MGMT label)\n",
    "# - Uses segmentation-based radiomics CSV (CaPTk_segm_*.csv)\n",
    "# - Uses UPENN-GBM_clinical_info_v2.1.csv for labels\n",
    "# - Does NOT save anything\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# If you run this from: .../MRI/code/\n",
    "FEATURES_PATH = \"../preprocessing_data/Radiomic_Features_CaPTk_segm_FLAIR_NC.csv\"\n",
    "CLINICAL_PATH = \"../preprocessing_data/UPENN-GBM_clinical_info_v2.1.csv\"\n",
    "\n",
    "# 1) Load\n",
    "df_feat = pd.read_csv(FEATURES_PATH)   # has: SubjectID + many feature columns\n",
    "df_clin = pd.read_csv(CLINICAL_PATH)  # has: ID, MGMT, ...\n",
    "\n",
    "# 2) Merge on subject key\n",
    "df = df_feat.merge(\n",
    "    df_clin[[\"ID\", \"MGMT\"]],\n",
    "    left_on=\"SubjectID\",\n",
    "    right_on=\"ID\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# 3) Build y from MGMT\n",
    "# Keep only the two clean classes; drop \"Not Available\" and \"Indeterminate\"\n",
    "df = df[df[\"MGMT\"].isin([\"Methylated\", \"Unmethylated\"])].copy()\n",
    "\n",
    "y = df[\"MGMT\"].map({\"Methylated\": 1, \"Unmethylated\": 0}).astype(int)\n",
    "\n",
    "# 4) Build X from numeric feature columns\n",
    "# Drop identifier/label columns\n",
    "X_all = df.drop(columns=[\"SubjectID\", \"ID\", \"MGMT\"], errors=\"ignore\")\n",
    "\n",
    "# Keep only numeric columns (radiomics should be numeric)\n",
    "X = X_all.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Optional: remove all-NaN or constant columns (safe cleanup)\n",
    "X = X.dropna(axis=1, how=\"all\")\n",
    "X = X.loc[:, X.nunique(dropna=True) > 1]\n",
    "\n",
    "print(\"Merged rows with usable MGMT:\", len(df))\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "print(\"Class balance (y):\", y.value_counts().to_dict())\n",
    "\n",
    "# Now you have:\n",
    "#   X: pandas DataFrame\n",
    "#   y: pandas Series (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11825800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Split verification ===\n",
      "Total rows in current df: 59\n",
      "Test IDs requested (file): 30\n",
      "Overlap (test IDs found in this df): 12\n",
      "Missing test IDs (not present in this df): 18\n",
      "First 10 missing: ['UPENN-GBM-00301_11', 'UPENN-GBM-00381_11', 'UPENN-GBM-00405_11', 'UPENN-GBM-00424_11', 'UPENN-GBM-00445_11', 'UPENN-GBM-00446_11', 'UPENN-GBM-00447_11', 'UPENN-GBM-00452_11', 'UPENN-GBM-00455_11', 'UPENN-GBM-00458_11']\n",
      "\n",
      "=== Split sizes ===\n",
      "Train: (47, 135) (47,)\n",
      "Test : (12, 135) (12,)\n",
      "Test class balance: {1: 6, 0: 6}\n"
     ]
    }
   ],
   "source": [
    "# Next step: verify test IDs exist in this dataframe, then split into train/test\n",
    "# - Assumes you already ran the previous block and have: df, X, y\n",
    "# - Assumes you already created a fixed test-id CSV (15/15) somewhere\n",
    "# - Does NOT save anything\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your fixed test IDs (edit if needed)\n",
    "TEST_IDS_PATH = \"../data/test_ids_core10_plus_extra20_seed340.csv\"  # columns: ID, y_mgmt (or ID,y)\n",
    "\n",
    "# 1) Load test IDs\n",
    "test_ids_df = pd.read_csv(TEST_IDS_PATH)\n",
    "\n",
    "# Robustly pick the ID column name from the test file\n",
    "if \"ID\" in test_ids_df.columns:\n",
    "    test_ids = set(test_ids_df[\"ID\"].astype(str))\n",
    "elif \"SubjectID\" in test_ids_df.columns:\n",
    "    test_ids = set(test_ids_df[\"SubjectID\"].astype(str))\n",
    "else:\n",
    "    raise ValueError(f\"Test IDs file must contain 'ID' or 'SubjectID'. Columns: {list(test_ids_df.columns)}\")\n",
    "\n",
    "# 2) Check overlap with current df (this df only contains subjects in FLAIR_NC + usable MGMT)\n",
    "df_ids = df[\"ID\"].astype(str)\n",
    "in_test_mask = df_ids.isin(test_ids)\n",
    "\n",
    "n_total = len(df)\n",
    "n_overlap = int(in_test_mask.sum())\n",
    "print(\"=== Split verification ===\")\n",
    "print(\"Total rows in current df:\", n_total)\n",
    "print(\"Test IDs requested (file):\", len(test_ids))\n",
    "print(\"Overlap (test IDs found in this df):\", n_overlap)\n",
    "\n",
    "# Optional: show missing IDs (from test list that are NOT in this df)\n",
    "missing = sorted(list(test_ids - set(df_ids)))\n",
    "print(\"Missing test IDs (not present in this df):\", len(missing))\n",
    "print(\"First 10 missing:\", missing[:10])\n",
    "\n",
    "# 3) Split (NOTE: for this specific feature file, test size may be <30 due to missing IDs)\n",
    "X_test = X.loc[in_test_mask].copy()\n",
    "y_test = y.loc[in_test_mask].copy()\n",
    "\n",
    "X_train = X.loc[~in_test_mask].copy()\n",
    "y_train = y.loc[~in_test_mask].copy()\n",
    "\n",
    "print(\"\\n=== Split sizes ===\")\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape, y_test.shape)\n",
    "print(\"Test class balance:\", y_test.value_counts().to_dict())\n",
    "\n",
    "# Now you have:\n",
    "#   X_train, y_train, X_test, y_test\n",
    "# ready for CV on train and final evaluation on test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef463b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost feature filtering ===\n",
      "Original #features: 135\n",
      "#features with importance > 0: 106\n",
      "\n",
      "Top features (up to 20):\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_Kurtosis  importance=0.048880\n",
      "FLAIR_NC_Intensity_TenthPercentile  importance=0.036599\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_QuartileCoefficientOfVariation  importance=0.026606\n",
      "FLAIR_NC_Intensity_StandardDeviation  importance=0.025830\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_Bin-13_Frequency  importance=0.024289\n",
      "FLAIR_NC_Intensity_QuartileCoefficientOfVariation  importance=0.023323\n",
      "FLAIR_NC_Morphologic_EllipseDiameter_Axis-2  importance=0.023193\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_NinetyFifthPercentile  importance=0.022022\n",
      "FLAIR_NC_Intensity_InterQuartileRange  importance=0.021736\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_Bin-6_Frequency  importance=0.018740\n",
      "FLAIR_NC_Intensity_Energy  importance=0.018419\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_Entropy  importance=0.018372\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_Bin-14_Probability  importance=0.018338\n",
      "FLAIR_NC_Morphologic_EquivalentSphericalPerimeter  importance=0.017509\n",
      "FLAIR_NC_GLSZM_Bins-16_Radius-1_GreyLevelVariance  importance=0.017453\n",
      "FLAIR_NC_GLRLM_Bins-16_Radius-1_ShortRunLowGreyLevelEmphasis  importance=0.017027\n",
      "FLAIR_NC_Intensity_CoefficientOfVariation  importance=0.015579\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_Bin-8_Frequency  importance=0.015112\n",
      "FLAIR_NC_Morphologic_EllipseDiameter_Axis-0  importance=0.015009\n",
      "FLAIR_NC_Histogram_Bins-16_Bins-16_RobustMeanAbsoluteDeviation1090  importance=0.014532\n"
     ]
    }
   ],
   "source": [
    "# 1) XGBoost training\n",
    "# Note: use eval_metric to avoid warning; keep it simple/robust.\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=340,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# 2) Get feature importances and select > 0\n",
    "importances = xgb.feature_importances_  # aligned with X_train.columns\n",
    "selected_mask = importances > 0\n",
    "\n",
    "selected_features = X_train.columns[selected_mask].tolist()\n",
    "\n",
    "# 3) Filter X_train / X_test to selected features\n",
    "X_train_sel = X_train[selected_features].copy()\n",
    "X_test_sel = X_test[selected_features].copy()\n",
    "\n",
    "# 4) Report how many features remain\n",
    "print(\"=== XGBoost feature filtering ===\")\n",
    "print(\"Original #features:\", X_train.shape[1])\n",
    "print(\"#features with importance > 0:\", len(selected_features))\n",
    "\n",
    "# Optional: show top-20 by importance (non-zero)\n",
    "top_idx = np.argsort(importances)[::-1]\n",
    "top_nonzero = [i for i in top_idx if importances[i] > 0][:20]\n",
    "print(\"\\nTop features (up to 20):\")\n",
    "for i in top_nonzero:\n",
    "    print(f\"{X_train.columns[i]}  importance={importances[i]:.6f}\")\n",
    "\n",
    "# Now use:\n",
    "#   X_train_sel, y_train\n",
    "#   X_test_sel,  y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2f3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\junse\\Documents\\research\\UPENN-GBM\\MRI\\Net\n",
      "Files: X_train.csv y_train.csv X_test.csv y_test.csv\n",
      "Shapes: X_train (47, 106) y_train 47 X_test (12, 106) y_test 12\n"
     ]
    }
   ],
   "source": [
    "# Save filtered (selected) features + labels into MRI/Net/\n",
    "# Creates 4 files:\n",
    "#   - Net/X_train.csv\n",
    "#   - Net/y_train.csv\n",
    "#   - Net/X_test.csv\n",
    "#   - Net/y_test.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Assumes these exist from previous steps:\n",
    "#   X_train_sel, y_train, X_test_sel, y_test\n",
    "\n",
    "# Resolve output directory robustly (works regardless of current working directory)\n",
    "# If running from MRI/code/, this will point to MRI/Net/\n",
    "base_dir = Path(\"..\").resolve()   # MRI/\n",
    "net_dir = base_dir / \"Net\"\n",
    "net_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure indices align and save without index\n",
    "X_train_sel.to_csv(net_dir / \"X_train.csv\", index=False)\n",
    "pd.Series(y_train).reset_index(drop=True).to_csv(net_dir / \"y_train.csv\", index=False, header=[\"y\"])\n",
    "\n",
    "X_test_sel.to_csv(net_dir / \"X_test.csv\", index=False)\n",
    "pd.Series(y_test).reset_index(drop=True).to_csv(net_dir / \"y_test.csv\", index=False, header=[\"y\"])\n",
    "\n",
    "print(\"Saved to:\", net_dir)\n",
    "print(\"Files:\",\n",
    "      (net_dir / \"X_train.csv\").name,\n",
    "      (net_dir / \"y_train.csv\").name,\n",
    "      (net_dir / \"X_test.csv\").name,\n",
    "      (net_dir / \"y_test.csv\").name)\n",
    "print(\"Shapes:\",\n",
    "      \"X_train\", X_train_sel.shape,\n",
    "      \"y_train\", len(y_train),\n",
    "      \"X_test\", X_test_sel.shape,\n",
    "      \"y_test\", len(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
